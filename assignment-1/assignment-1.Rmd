---
title: "R Notebook"
output: html_notebook
---


<!-- This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.  

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).
-->

Task 1: Explore a small dataset (40 points)
When you do data mining (DM), you will need to check for data quality, manipulate data, as well as to build and evaluate models. You can write your own applications for this purpose, and in many commercial projects this is exactly what you are expected to do, but to start with DM and to carry out typical tasks I find it better to use a software that is specifically written for this purpose. In this first assignment, the aim is that you get familiar with your chosen DM software. You should learn to use it on a basic level, and carry out elementary DM tasks, so you will be prepared to take on more challenging ones coming to you in the form of subsequent assignments.
Tasks and Expectations
You (as a group) should start by choosing a certain DM software. Here’s a list of corresponding rules:
• If you are uncertain about this choice, I recommend you to pick RapidMiner or WEKA. If you have a favourite programming language, you can also look for packages available in that language.
• This is not a choice for the whole course. If you find out later that another software is better suited
for a task at hand, you can switch to that in subsequent assignments.
###Task 1.A – Exploration (20 points)
Once you have chosen (and perhaps installed) the software, here is your first task:
• Download the ODI dataset from BB. ODI stands for Own Dataset Initiative.
• Load the dataset, which will be in CSV format as well as Excel, into your software. CSV stands
for comma separated values, though it is more common these days to separate values with semi- colon (;). Nevertheless, the format is still called CSV even if the separator is a tab character or whatever else defined by the dataset creator.
• Notice all sorts of properties of the dataset: how many records are there, how many attributes, what kinds of attributes are there, ranges of values, distribution of values, relationships between attributes, and so on. Notice if something is interesting (to you, or in general), make sure you write it down if you find something worth mentioning.
• Make various plots of the data. Is there something interesting worth reporting? Report the figures, discuss what is in them. What meaning do those bars, lines, dots, etc. convey? Please select essential and interesting plots for discussion, as you have limited space for reporting your findings (see details in a later section).
To sum up, you will need to explore the dataset, and report findings that are essential to get an idea about the data, and also, findings that make it possible to learn something interesting about the dataset.

package installation
#####installing
```{r}
# rm(list = setdiff(ls(), lsf.str()))
# 
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
```
#####loading
```{r}
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
```

***
***
***

loading the data 
change the path based on your own path
```{r}
library(readr)

#file_path = file.path( "~", "Google Drive","VU", "Data mining" ,"SmsCollection.csv")
file_path = file.path( "ODI-2017.csv")
ODI <- read.csv(file_path,header =TRUE,sep = ",",stringsAsFactors = TRUE,fill = TRUE)

class(ODI)


colnames(ODI)[1] <- "time"
colnames(ODI)[2] <- "program"
colnames(ODI)[3] <- "mach_lrn"
colnames(ODI)[4] <- "info_ret"
colnames(ODI)[5] <- "stats"
colnames(ODI)[6] <- "db"
colnames(ODI)[7] <- "gender"
colnames(ODI)[8] <- "chocolate"
colnames(ODI)[9] <- "birthday"
colnames(ODI)[10] <- "age"
colnames(ODI)[11] <- "neighbors"
colnames(ODI)[12] <- "stand"
colnames(ODI)[13] <- "money"
colnames(ODI)[14] <- "random"
colnames(ODI)[15] <- "bed_time"
colnames(ODI)[16] <- "good_day_1"
colnames(ODI)[17] <- "good_day_2"
              
head(ODI)
ODI$time <- as.Date(ODI$time, format = "%d/%m/%Y %H:%M:%S")

```

```{r}
library(xtable)
# print(xtable(summary(ODI)))
# print(xtable(summary(ODI)),floating=FALSE,latex.environments=NULL)
print(xtable(summary(ODI[,1:4])),floating=FALSE,latex.environments=NULL,booktabs=TRUE)
print(xtable(summary(ODI[,5:7])),floating=FALSE,latex.environments=NULL,booktabs=TRUE)
print(xtable(summary(ODI[,8:11])),floating=FALSE,latex.environments=NULL,booktabs=TRUE)
print(xtable(summary(ODI[,12:16])),floating=FALSE,latex.environments=NULL,booktabs=TRUE)
```
### data exploration
#### random numbers
```{r}
f <- ODI$random
f <- as.numeric(levels(f)[f])
head(f)
length(f)
f <- na.omit(f);
head(f)
length(f)
f
```

pure values histogram
```{r}
barplot(table(ODI$machine_learning))

```
probibility values histogram
```{r}
barplot(prop.table(table(ODI$machine_learning)))
```

good day
```{r}
gd1 <- data.frame(ODI$good_day_1)
gd2 <- data.frame(ODI$good_day_2)

good_day <- cbind(gd1,gd2)
head(good_day)


#barplot(table(cat(ODI$good_day_1 , ODI$good_day_2))]

```

text mining from http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know

```{r,fig.fullwidth=TRUE,fig.height=3}
gd1 <- ODI$good_day_1
gd2 <- ODI$good_day_2
# combining good day answers 
gd <- data.frame(gd1,gd2)
docs <- Corpus(VectorSource(gd[,2]))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
#docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
#docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
#docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
#docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```
#IDEAS
sleep as good nday and when they went to bed
chocolate and gender
age and bed time

sex and random
```{r}
# plot(ODI$random,ODI$gender)
random_number <- as.numeric(ODI$random)
summary(ODI$gender)
# plot(ODI$gender,ODI$random)
```


others
```{r}
#hist(ODI$time)
#plot(data = data, x = $Timestamp)

#install.packages("plotly")
#library(plotly)
#packageVersion('plotly')



#p <- plot_ly(ODI, labels = ~machine_learning ,values = count(~machine_learning), type = 'pie')
#p

# findFreqTerms(dtm, lowfreq = 4)
# findAssocs(dtm, terms = "freedom", corlimit = 0.3)
# barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
#         col ="lightblue", main ="Most frequent words",
#         ylab = "Word frequencies")

```
#classification / regression
Task 1.B – Basic classification/regression (20 points)
Our main goal with this task is that you learn to run simple experiments. Here’s the task list:
• Take the ODI dataset and load it. Alternatively, you can download a dataset of your own choice
from the web, and load that. If you opt for a downloaded dataset, write down why that interests
you, and why it is suited for classification/regression.
• Design and run at least one classification/regression experiment on the data, with cross validation.
You will probably need to go through a couple of tutorials to accomplish this task. Don’t worry if you don’t know what cross validation is, we will cover that later. I just require you to use that to avoid that people do this task with one line of code.
• Note the setup you use, the results you get, and try to understand what happened, what models have been built, what numbers have been outputted by the algorithm you used.
• Try at least two algorithms, and try to interpret the differences in outcome of the experiments. This doesn’t need to be a deep analysis, remember that this assignment is only to get you started. We will learn more about performance measures and comparison later.
Once you are done with this task, write up your findings.
#### before feeding the data we remove noise, redundancy and insignificant variables.
redundancy can be like age and birthday
insignificant is when they dont conterbute to the outcome




decition tree


```{r}
# Load the party package. It will automatically load other dependent packages.
library(party)



# Give the chart file a name.
#png(file = "decision_tree.png")

# Create the tree.
  output.tree <- ctree(
  gender ~  mach_lrn + stats +  db + info_ret + chocolate + bed_time + program  ,  
  data = ODI)

  
  print(output.tree)
# Plot the tree.
plot(output.tree)

# Save the file.
#dev.off()
```


do logistical regression  and assosiation 


```{r}
# levels(ODI$gender)
# #levels(ODI$chocolate)
# reg=lm(random~gender,data=ODI)
# #summary(reg)
#logistic regression model
# set.seed(88)
# train <- sample.split(ODI, SplitRatio = 0.75)
# validation <- sample.split(ODI, SplitRatio = 0.25)
# test <- sample.split(ODI, SplitRatio = 0.75)
# model <- lm(formula = age ~  chocolate + gender + program + money + bed_time, data = train)
# compare models
# fit1 <- lm(age ~  gender + chocolate, data = ODI)
# # fit2 <- lm(age ~  chocolate + gender + program + money , data = ODI)
# # anova(fit1, fit2)
#
# model <- glm (formula = age ~  chocolate + gender + program + money + bed_time, data = ODI)
# summary(model)
# predict <- predict(model, newdata = validation)

yourData <- ODI
#Randomly shuffle the data
yourData<-yourData[sample(nrow(yourData)),]

#Create 10 equally size folds
folds <- cut(seq(1,nrow(yourData)),breaks=10,labels=FALSE)

#Perform 10 fold cross validation
for(i in 1:10){
    #Segement your data by fold using the which() function
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- yourData[testIndexes, ]
    trainData <- yourData[-testIndexes, ]
    
    m <- lm(formula = age ~  chocolate + gender   ,data= trainData)
    p <- predict(m, newdata = testData)
    print(cor(testData$age, p))
}


```
#assosiation rules
```{r}
library(arules)
# find association rules with default settings
 # 1, 10, 11, 13, 14
ODI$age = as.factor(ODI$age)
                    
rules <- apriori(ODI[-c(1,11,13,14)])
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
# inspect(rules)
```
# find redundant rules
```{r}
 
subset.matrix <- is.subset(rules.sorted, rules.sorted)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >= 1
# which(redundant)
# remove redundant rules
rules.pruned <- rules.sorted[!redundant]
inspect(rules.pruned)
```
#visualize
```{r}
library(arulesViz)
# plot(rules)
# plot(rules[1:10], method="graph", control=list(type="items"))
plot(rules.sorted[1:20], method="paracoord", control=list(reorder=TRUE))
```


```{r}
# Cross validation (customized)
dat <- ODI
library(plyr)   # progress bar
library(caret)  # confusion matrix
# False positive rate
fpr <- NULL
# False negative rate
fnr <- NULL

# Number of iterations
k <- 400

# Initialize progress bar
pbar <- create_progress_bar('text')
pbar$init(k)

# Accuracy
acc <- NULL

set.seed(123)

for(i in 1:k)
{
    # Train-test splitting
    # 95% of samples -> fitting
    # 5% of samples -> testing
    smp_size <- floor(0.95 * nrow(dat))
    index <- sample(seq_len(nrow(dat)),size=smp_size)
    train <- dat[index, ]
    test <- dat[-index, ]
    
    fit7 <- glm(formula = age ~    gender + chocolate ,data= train )
    
    results_prob <- predict(fit7, test,type='response')
  
    # # Fitting
    # model <- lm(age~random,data=train)
    # 
    # # Predict results
    # results_prob <- predict(model,newdata = test,type='response')
    
    # If prob > 0.5 then 1, else 0
    results <- ifelse(results_prob > 0.5,1,0)
    
    # Actual answers
    answers <- test$age
    
    # Accuracy calculation
    misClasificError <- mean(answers != results)
    
    # Collecting results
    acc[i] <- 1-misClasificError
    
    # Confusion matrix
    # cm <- confusionMatrix(data=results, reference=answers)
    # fpr[i] <- cm$table[2]/(nrow(dat)-smp_size)
    # fnr[i] <- cm$table[3]/(nrow(dat)-smp_size)
    
    pbar$step()
}

# Average accuracy of the model
mean(acc)

# par(mfcol=c(1,2))

# Histogram of accuracy
# hist(acc,xlab='Accuracy',ylab='Freq',
#      col='cyan',border='blue',density=30)
# 
# # Boxplot of accuracy
# boxplot(acc,col='cyan',border='blue',horizontal=T,xlab='Accuracy',
#         main='Accuracy CV')

# Confusion matrix and plots of fpr and fnr
# mean(fpr)
# mean(fnr)
# hist(fpr,xlab='% of fnr',ylab='Freq',main='FPR',
#      col='cyan',border='blue',density=30)
# hist(fnr,xlab='% of fnr',ylab='Freq',main='FNR',
#      col='cyan',border='blue',density=30)

# model <- glm(formula = age ~  bed_time + gender + chocolate + program,data= ODI )
# p = predict(model,ODI)
# cor(ODI$age,p)

```

```{r}
# in this cross validation example, we use the iris data set to 
# predict the Sepal Length from the other variables in the dataset 
# with the random forest model 
library(plyr)
library(randomForest)

data <- ODI

k = 10 #Folds

# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k

# prediction and testset data frames that we add to with each iteration over
# the folds

prediction <- data.frame()
testsetCopy <- data.frame()

#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)

for (i in 1:k){
  # remove rows with id i from dataframe to create training set
  # select rows with id i to create test set
  trainingset <- subset(data, id %in% list[-i])
  testset <- subset(data, id %in% c(i))
  
  # run a random forest model
  # mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
  mymodel <- glm(age ~ gender + chocolate , data = trainingset)
  
  # remove response column 1, Sepal.Length
  temp <- as.data.frame(predict(mymodel, testset[,-10]))
  # append this iteration's predictions to the end of the prediction data frame
  prediction <- rbind(prediction, temp)
  
  # append this iteration's test set to the test set copy data frame
  # keep only the Sepal Length Column
  testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
  
  progress.bar$step()
}

# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)

# As an example use Mean Absolute Error as Evalution 
summary(result$Difference)

```

