# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k
# prediction and testset data frames that we add to with each iteration over
# the folds
prediction <- data.frame()
testsetCopy <- data.frame()
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for (i in 1:k){
# remove rows with id i from dataframe to create training set
# select rows with id i to create test set
trainingset <- subset(data, id %in% list[-i])
testset <- subset(data, id %in% c(i))
# run a random forest model
# mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
mymodel <- glm(age ~ gender + chocolate, data = trainingset)
# remove response column 1, Sepal.Length
temp <- as.data.frame(predict(mymodel, testset[,-10]))
# append this iteration's predictions to the end of the prediction data frame
prediction <- rbind(prediction, temp)
# append this iteration's test set to the test set copy data frame
# keep only the Sepal Length Column
testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
progress.bar$step()
}
# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)
# As an example use Mean Absolute Error as Evalution
summary(result$Difference)
# in this cross validation example, we use the iris data set to
# predict the Sepal Length from the other variables in the dataset
# with the random forest model
library(plyr)
library(randomForest)
data <- ODI
k = 1000 #Folds
# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k
# prediction and testset data frames that we add to with each iteration over
# the folds
prediction <- data.frame()
testsetCopy <- data.frame()
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for (i in 1:k){
# remove rows with id i from dataframe to create training set
# select rows with id i to create test set
trainingset <- subset(data, id %in% list[-i])
testset <- subset(data, id %in% c(i))
# run a random forest model
# mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
mymodel <- glm(age ~ gender + chocolate, data = trainingset)
# remove response column 1, Sepal.Length
temp <- as.data.frame(predict(mymodel, testset[,-10]))
# append this iteration's predictions to the end of the prediction data frame
prediction <- rbind(prediction, temp)
# append this iteration's test set to the test set copy data frame
# keep only the Sepal Length Column
testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
progress.bar$step()
}
# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)
# As an example use Mean Absolute Error as Evalution
summary(result$Difference)
# Cross validation (customized)
dat <- ODI
library(plyr)   # progress bar
library(caret)  # confusion matrix
# False positive rate
fpr <- NULL
# False negative rate
fnr <- NULL
# Number of iterations
k <- 400
# Initialize progress bar
pbar <- create_progress_bar('text')
pbar$init(k)
# Accuracy
acc <- NULL
set.seed(123)
for(i in 1:k)
{
# Train-test splitting
# 95% of samples -> fitting
# 5% of samples -> testing
smp_size <- floor(0.95 * nrow(dat))
index <- sample(seq_len(nrow(dat)),size=smp_size)
train <- dat[index, ]
test <- dat[-index, ]
fit7 <- glm(formula = age ~    gender + chocolate ,data= train )
results_prob <- predict(fit7, test,type='response')
# # Fitting
# model <- lm(age~random,data=train)
#
# # Predict results
# results_prob <- predict(model,newdata = test,type='response')
# If prob > 0.5 then 1, else 0
results <- ifelse(results_prob > 0.5,1,0)
# Actual answers
answers <- test$age
# Accuracy calculation
misClasificError <- mean(answers != results)
# Collecting results
acc[i] <- 1-misClasificError
# Confusion matrix
# cm <- confusionMatrix(data=results, reference=answers)
# fpr[i] <- cm$table[2]/(nrow(dat)-smp_size)
# fnr[i] <- cm$table[3]/(nrow(dat)-smp_size)
pbar$step()
}
# Average accuracy of the model
mean(acc)
# par(mfcol=c(1,2))
# Histogram of accuracy
# hist(acc,xlab='Accuracy',ylab='Freq',
#      col='cyan',border='blue',density=30)
#
# # Boxplot of accuracy
# boxplot(acc,col='cyan',border='blue',horizontal=T,xlab='Accuracy',
#         main='Accuracy CV')
# Confusion matrix and plots of fpr and fnr
# mean(fpr)
# mean(fnr)
# hist(fpr,xlab='% of fnr',ylab='Freq',main='FPR',
#      col='cyan',border='blue',density=30)
# hist(fnr,xlab='% of fnr',ylab='Freq',main='FNR',
#      col='cyan',border='blue',density=30)
# model <- glm(formula = age ~  bed_time + gender + chocolate + program,data= ODI )
# p = predict(model,ODI)
# cor(ODI$age,p)
cor((result$Actual , result$Predicted))
cor(result$Actual , result$Predicted)
View(result)
# in this cross validation example, we use the iris data set to
# predict the Sepal Length from the other variables in the dataset
# with the random forest model
library(plyr)
library(randomForest)
data <- ODI
k = 10 #Folds
# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k
# prediction and testset data frames that we add to with each iteration over
# the folds
prediction <- data.frame()
testsetCopy <- data.frame()
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for (i in 1:k){
# remove rows with id i from dataframe to create training set
# select rows with id i to create test set
trainingset <- subset(data, id %in% list[-i])
testset <- subset(data, id %in% c(i))
# run a random forest model
# mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
mymodel <- glm(age ~ gender + chocolate, data = trainingset)
# remove response column 1, Sepal.Length
temp <- as.data.frame(predict(mymodel, testset[,-10]))
# append this iteration's predictions to the end of the prediction data frame
prediction <- rbind(prediction, temp)
# append this iteration's test set to the test set copy data frame
# keep only the Sepal Length Column
testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
progress.bar$step()
}
# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)
# As an example use Mean Absolute Error as Evalution
summary(result$Difference)
# in this cross validation example, we use the iris data set to
# predict the Sepal Length from the other variables in the dataset
# with the random forest model
library(plyr)
library(randomForest)
data <- ODI
k = 10 #Folds
# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k
# prediction and testset data frames that we add to with each iteration over
# the folds
prediction <- data.frame()
testsetCopy <- data.frame()
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for (i in 1:k){
# remove rows with id i from dataframe to create training set
# select rows with id i to create test set
trainingset <- subset(data, id %in% list[-i])
testset <- subset(data, id %in% c(i))
# run a random forest model
# mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
mymodel <- glm(age ~ gender + chocolate + bed_time, data = trainingset)
# remove response column 1, Sepal.Length
temp <- as.data.frame(predict(mymodel, testset[,-10]))
# append this iteration's predictions to the end of the prediction data frame
prediction <- rbind(prediction, temp)
# append this iteration's test set to the test set copy data frame
# keep only the Sepal Length Column
testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
progress.bar$step()
}
# in this cross validation example, we use the iris data set to
# predict the Sepal Length from the other variables in the dataset
# with the random forest model
library(plyr)
library(randomForest)
data <- ODI
k = 10 #Folds
# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k
# prediction and testset data frames that we add to with each iteration over
# the folds
prediction <- data.frame()
testsetCopy <- data.frame()
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)
for (i in 1:k){
# remove rows with id i from dataframe to create training set
# select rows with id i to create test set
trainingset <- subset(data, id %in% list[-i])
testset <- subset(data, id %in% c(i))
# run a random forest model
# mymodel <- randomForest(age ~ gender + chocolate, data = trainingset, ntree = 100)
mymodel <- glm(age ~ gender + chocolate , data = trainingset)
# remove response column 1, Sepal.Length
temp <- as.data.frame(predict(mymodel, testset[,-10]))
# append this iteration's predictions to the end of the prediction data frame
prediction <- rbind(prediction, temp)
# append this iteration's test set to the test set copy data frame
# keep only the Sepal Length Column
testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,10]))
progress.bar$step()
}
# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)
# As an example use Mean Absolute Error as Evalution
summary(result$Difference)
View(result)
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
rules <- apriori(ODI[-c(1,10,11,13,14)])
rules.sorted <- sort(rules, by="lift")
inspect(head(rules.sorted))
# inspect(rules)
cor(result$Actual , result$Predicted)
rules.pruned
rules.sorted
print(rules.sorted)
inspect
inspect(rules.sorted)
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
rules <- apriori(ODI[-c(1,10,11,13)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
rules <- apriori(ODI[-c(1,10,11,14)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
rules <- apriori(ODI[-c(1,10,13,14)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
rules <- apriori(ODI[-c(1,11,13,14)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI[10] = as.factor(ODI[10])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI[c(10)] = as.factor(ODIc([10)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI[c(10)] = as.factor(ODIc([10)]))
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI$age = as.factor(ODI$age
rules <- apriori(ODI[-c(1,11,13,14)])
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI$age = as.factor(ODI$age)
rules <- apriori(ODI[-c(1,11,13,14)])
rules.sorted <- sort(rules, by="lift")
inspect(head(rules.sorted))
# inspect(rules)
# inspect(rules)
inspect(rules)
subset.matrix <- is.subset(rules.sorted, rules.sorted)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >= 1
# which(redundant)
# remove redundant rules
rules.pruned <- rules.sorted[!redundant]
inspect(rules.pruned)
library(arules)
# find association rules with default settings
# 1, 10, 11, 13, 14
ODI$age = as.factor(ODI$age)
rules <- apriori(ODI[-c(1,11,13,14)])
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
# inspect(rules)
library(readr)
SmsCollection <- read_delim("~/Developer/Data-Mining/assignment-1/SmsCollection.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(SmsCollection)
summary(SmsCollection)
levels(SmsCollection)
library(Weka)
library(Weka)
library(RWeka)
StringToWordVector()
m <- J48(v1~., data = SmsCollection)
m <- J48(v1~., data = SmsCollection)
head(SmsCollection)
m <- J48(label~., data = SmsCollection)
m <- J48(label~text, data = SmsCollection)
m1 <- Normalize(~., data = SmsCollection)
m1
m2 <- Discretize(play ~., data = SmsCollection)
View(m1)
m2 <- Discretize(label ~., data = SmsCollection)
m <- J48(label~text, data = m1)
m2 <- Discretize(label ~., data = ma)
m2 <- Discretize(label ~., data = m1)
View(m1)
J48(label ~ ., data = SmsCollection)
WordTokenizer(SmsCollection, control = NULL)
WordTokenizer(SmsCollection$text, control = NULL)
J48(label ~ text, data = SmsCollection)
ID3 <- make_Weka_classifier("weka/classifiers/trees/Id3")
ID3(`label` ~ ., data = SmsCollection)
ID3(label ~ ., data = m1)
J48(label ~ text, data = SmsCollection)
J48(label ~ text, data = m1)
J48(label ~ text, data = m1)
## Use some example data.
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1$text <- as.data.frame(m1$text)
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1$text <- data.frame(m1$text)
## Identify a decision tree.
m <- J48(label~., data = m1)
View(m1)
## Use some example data.
m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1 <- SmsCollection
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1 <- normalize(SmsCollection)
## Use some example data.
m1 <- SmsCollection
NGramTokenizer(m1, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1 <- SmsCollection
m1$tokens <- NGramTokenizer(m1$text, control = NULL)
## Use some example data.
m1 <- SmsCollection
m1$tokens <- NGramTokenizer(m, control = NULL)
## Use some example data.
m1 <- SmsCollection
m2 <- NGramTokenizer(m, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m1)
## Use some example data.
m1 <- SmsCollection
m2 <- NGramTokenizer(m, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m2)
m2
## Use some example data.
m1 <- SmsCollection
# m2 <- NGramTokenizer(m, control = NULL)
m2 < - WordTokenizer(x, control = NULL)
## Use some example data.
m1 <- SmsCollection
# m2 <- NGramTokenizer(m, control = NULL)
m2 < - WordTokenizer(m1, control = NULL)
## Use some example data.
m1 <- SmsCollection
m2 <- NGramTokenizer(m1, control = NULL)
# m2 < - WordTokenizer(m1, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(label~., data = m2)
m2
## Use some example data.
m1 <- SmsCollection
m2 <- NGramTokenizer(m1$text, control = NULL)
## Use some example data.
m1 <- SmsCollection
m2 <- NGramTokenizer(m1, control = NULL)
# m2 < - WordTokenizer(m1, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(~., data = m2)
## Use some example data.
m1 <- SmsCollection
# m2 <- NGramTokenizer(m1, control = NULL)
# m2 < - WordTokenizer(m1, control = NULL)
# m1 <- data.frame(m1)
## Identify a decision tree.
m <- J48(~., data = m1)
WOW(SmsCollection)
WOW(J48)
library(readr)
#file_path = file.path( "~", "Google Drive","VU", "Data mining" ,"SmsCollection.csv")
file_path = file.path( "ODI-2017.csv")
ODI <- read.csv(file_path,header =TRUE,sep = ",",stringsAsFactors = TRUE,fill = TRUE)
class(ODI)
colnames(ODI)[1] <- "time"
colnames(ODI)[2] <- "program"
colnames(ODI)[3] <- "mach_lrn"
colnames(ODI)[4] <- "info_ret"
colnames(ODI)[5] <- "stats"
colnames(ODI)[6] <- "db"
colnames(ODI)[7] <- "gender"
colnames(ODI)[8] <- "chocolate"
colnames(ODI)[9] <- "birthday"
colnames(ODI)[10] <- "age"
colnames(ODI)[11] <- "neighbors"
colnames(ODI)[12] <- "stand"
colnames(ODI)[13] <- "money"
colnames(ODI)[14] <- "random"
colnames(ODI)[15] <- "bed_time"
colnames(ODI)[16] <- "good_day_1"
colnames(ODI)[17] <- "good_day_2"
head(ODI)
ODI$time <- as.Date(ODI$time, format = "%d/%m/%Y %H:%M:%S")
plot(age)
attach(ODI)
plot
plot(age)
hist(AGE)
hist(age)
hist(gender)
hist(gender,age)
hist(age,gender)
library(plotly)
hist(age,gender)
hist(age,random)
hist(age,bed_time)
par(mfrow=c(2,2))
hist(age)
hist(gender)
plot(gender)
plot(chocolate)
plot(program)
plot(random,age)
plot(age,random)
hist(age,random)
scatter(age,random)
scatter.smooth(random)
scatter.smooth(age~random)
par(mfrow=c(2,2))
plot(gender)
plot(age)
par(mfrow=c(2,2))
plot(gender)
hist(age)
plot(bed_time)
plot(chocolate)
par(mfrow=c(2,2))
plot(gender , main="Gender plot")
hist(age, main="Age plot")
plot(bed_time, main="Bed time plot")
plot(chocolate, main="Chocolate plot")
par(mfrow=c(2,2))
plot(gender , main="Gender plot")
hist(age, main="Age plot")
plot(bed_time, main="Bed time plot")
plot(chocolate, main="Chocolate plot")
